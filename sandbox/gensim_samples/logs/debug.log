WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 220-641-344
INFO:werkzeug: * Detected change in '/home/diegoami/PycharmProjects/Newscollection/gensim_samples/gensim_service.py', reloading
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 220-641-344
INFO:werkzeug:127.0.0.1 - - [18/Sep/2017 22:59:29] "OPTIONS / HTTP/1.1" 200 -
INFO:gensim.utils:loading Dictionary object from data/tech_posts_6.json.dict
INFO:gensim.utils:loaded data/tech_posts_6.json.dict
INFO:gensim.corpora.indexedcorpus:loaded corpus index from data/tech_posts_6.json.mm.index
INFO:gensim.matutils:initializing corpus reader from data/tech_posts_6.json.mm
INFO:gensim.matutils:accepted corpus with 600 documents, 13852 features, 147357 non-zero entries
INFO:gensim.utils:loading LsiModel object from data/tech_posts_6.json.lsi
INFO:gensim.utils:loading id2word recursively from data/tech_posts_6.json.lsi.id2word.* with mmap=None
INFO:gensim.utils:setting ignored attribute projection to None
INFO:gensim.utils:setting ignored attribute dispatcher to None
INFO:gensim.utils:loaded data/tech_posts_6.json.lsi
INFO:gensim.utils:loading LsiModel object from data/tech_posts_6.json.lsi.projection
INFO:gensim.utils:loaded data/tech_posts_6.json.lsi.projection
INFO:gensim.utils:loading MatrixSimilarity object from data/tech_posts_6.json.index
INFO:gensim.utils:loaded data/tech_posts_6.json.index
DEBUG:root:{'text': 'The mind behind Ethereum, Vitalik Buterin, is matter-of-fact about the crypto. In short, he believes what interviewer Naval Ravikant called “brain virus” is the true future of security and economics and, with the right incentives, Ethereum can replace things like credit card networks and even gaming servers.\n\nButerin separates the world into two kinds of people.\n\n“There’s the average person who’s already heard of bitcoin and the average person who hasn’t,” he said. His project itself builds upon that notion by adding more utility to the blockchain, thereby creating something everyone will want to hear about.\n\n“Where Ethereum comes from is basically you take the idea of crypto economics and the kinds of economic incentives that keeps things like bitcoin going to create decentralized networks with memory for a whole bunch of applications,” he said. “A good blockchain application is something that needs decentralization and some kind of shared memory.”\n\nThat’s what he’s building and hopes others will build on the Ethereum network.\n\n\nVitalik Buterin (Ethereum Foundation) and Naval Ravikant at TechCrunch Disrupt SF 2017\n\nRight now the network is a bit too slow for most mainstream applications.\n\n“Bitcoin is processing a bit less than 3 transactions per second,” he said. “Ethereum is doing five a second. Uber gives 12 rides a second. It will take a couple of years for the blockchain to replace Visa.”\n\nButerin doesn’t think everything should run on the blockchain but many things can. As the technology expands it can grow to replace many services that require parallelization\xa0— that is programs that should run at the same time.\n\n“You could run StarCraft on the blockchain. Those kinds of things are possible. High level of security and scalability allows all these various other things to be built on top. Ethereum is a secure base layer that doesn’t have too many features.”\n\n“Crypto is all about incentives on various levels,” he said. “You cannot reason about the security of blockchain consensus protocols without incentives.”', 'n_articles': 10}
INFO:werkzeug:127.0.0.1 - - [18/Sep/2017 22:59:29] "POST / HTTP/1.1" 200 -
INFO:werkzeug:127.0.0.1 - - [18/Sep/2017 22:59:48] "OPTIONS / HTTP/1.1" 200 -
INFO:gensim.utils:loading Dictionary object from data/tech_posts_6.json.dict
INFO:gensim.utils:loaded data/tech_posts_6.json.dict
INFO:gensim.corpora.indexedcorpus:loaded corpus index from data/tech_posts_6.json.mm.index
INFO:gensim.matutils:initializing corpus reader from data/tech_posts_6.json.mm
INFO:gensim.matutils:accepted corpus with 600 documents, 13852 features, 147357 non-zero entries
INFO:gensim.utils:loading LsiModel object from data/tech_posts_6.json.lsi
INFO:gensim.utils:loading id2word recursively from data/tech_posts_6.json.lsi.id2word.* with mmap=None
INFO:gensim.utils:setting ignored attribute projection to None
INFO:gensim.utils:setting ignored attribute dispatcher to None
INFO:gensim.utils:loaded data/tech_posts_6.json.lsi
INFO:gensim.utils:loading LsiModel object from data/tech_posts_6.json.lsi.projection
INFO:gensim.utils:loaded data/tech_posts_6.json.lsi.projection
INFO:gensim.utils:loading MatrixSimilarity object from data/tech_posts_6.json.index
INFO:gensim.utils:loaded data/tech_posts_6.json.index
DEBUG:root:{'text': 'Report: Facebook gave special investigator Robert Mueller detailed info on Russian ad buys\nPosted Sep 15, 2017 by Jonathan Shieber (@jshieber)\nNext Story\nFutureFuel.io adds new features to make paying off student loans\xa0easier\n\nAn official for Facebook told TechCrunch that the company is “continuing to cooperate with the relevant U.S. authorities,” as investigations into the Russian hack of last year’s presidential election continue to expand. In the latest development, authorities are now investigating how agents used online advertising on social networks and search platforms, and tech companies are being forced to hand over new, sensitive information to investigators as a result.\n\nIn some cases, that means providing different information to different investigations, as\xa0The Wall Street Journal\xa0is reporting today.\n\nFacebook has apparently turned over more detailed information to the special prosecutor, Robert Mueller, than the company shared with Congress last week, the Journal reports.\n\nMueller’s investigation has received copies of the Russian-bought ads and details about the specific account information and targeting criteria the buyers used to distribute their ads, according to the Journal, citing people familiar with the matter.\n\nIt’s likely that Facebook was compelled to turn over the information because the investigating team received a search warrant.\n\nIf indeed, Mueller is using warrants, then it’s likely that Facebook won’t be the only tech company that may be forced to reveal information about potential clandestine advertising buys, which Russian agents are alleged to have made in order to influence the U.S. election.\n\nThe Journal reports that Mueller’s team could have gotten information that Facebook withheld from Congress because of concerns around privacy laws or fears of disrupting the Mueller probe. My guess is that Facebook is likely also thinking that the Mueller investigation is a tighter ship and less likely to leak details of the ads whereas Congressional staffers could leak like sieves.\n\nIt’s clear that Facebook has no interest in revealing details of the ad buys, or telling individuals whether they were targets of what amounts to a Russian plot to influence the U.S. election.\n\nIt’s something members of the tech community have taken Facebook to task for already.', 'n_articles': 10}
INFO:werkzeug:127.0.0.1 - - [18/Sep/2017 22:59:49] "POST / HTTP/1.1" 200 -
INFO:werkzeug: * Detected change in '/home/diegoami/PycharmProjects/Newscollection/gensim_samples/gensim_lib.py', reloading
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 220-641-344
INFO:werkzeug: * Detected change in '/home/diegoami/PycharmProjects/Newscollection/gensim_samples/gensim_lib.py', reloading
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 220-641-344
INFO:werkzeug:127.0.0.1 - - [18/Sep/2017 23:04:11] "OPTIONS / HTTP/1.1" 200 -
INFO:gensim.utils:loading Dictionary object from data/tech_posts_6.json.dict
INFO:gensim.utils:loaded data/tech_posts_6.json.dict
INFO:gensim.corpora.indexedcorpus:loaded corpus index from data/tech_posts_6.json.mm.index
INFO:gensim.matutils:initializing corpus reader from data/tech_posts_6.json.mm
INFO:gensim.matutils:accepted corpus with 600 documents, 13852 features, 147357 non-zero entries
INFO:gensim.utils:loading LsiModel object from data/tech_posts_6.json.lsi
INFO:gensim.utils:loading id2word recursively from data/tech_posts_6.json.lsi.id2word.* with mmap=None
INFO:gensim.utils:setting ignored attribute projection to None
INFO:gensim.utils:setting ignored attribute dispatcher to None
INFO:gensim.utils:loaded data/tech_posts_6.json.lsi
INFO:gensim.utils:loading LsiModel object from data/tech_posts_6.json.lsi.projection
INFO:gensim.utils:loaded data/tech_posts_6.json.lsi.projection
INFO:gensim.utils:loading MatrixSimilarity object from data/tech_posts_6.json.index
INFO:gensim.utils:loaded data/tech_posts_6.json.index
DEBUG:root:{'text': 'Why Dropbox decided to drop AWS and build its own infrastructure and network\nPosted Sep 15, 2017 by Ron Miller (@ron_miller)\nNext Story\nUpcoming versions of Google Chrome will let you permanently mute sites, block autoplaying\xa0videos\n\nThere is always a tension inside companies about whether to build or to buy, whatever the need. A few years ago Dropbox decided it was going to move the majority of its infrastructure requirements from AWS into its own data centers. As you can imagine, it took a monumental effort, but the company believed that the advantages of controlling its own destiny would be worth all of the challenges they faced to get there.\n\nFor starters, a company like Dropbox is dealing with a huge number of customers storing an enormous amount of data. The latest numbers are 500 million users and 200,000 business customers. When they made the transition, they had to move an epic 500 petabytes — that’s five followed by 17 zeros — that had been sitting on AWS servers. (They still use AWS for some workloads.)\n\nThe first step was building the infrastructure to replace it. We’re talking about a company that had 1500 employees, with just around a dozen on the infrastructure team. This was not a huge operation, yet what they were trying to do was build something themselves at web scale that only a small number of companies with much larger teams had tried to this point.\n\nThat included building and equipping three US data centers. It also meant building the network backbone, the infrastructure that facilitated the connections between the US data centers and other facilities they had located throughout the world. When you open Dropbox and request a file, you want your file to download pretty much instantaneously without latency, and it was up to the team to ensure that happened, while trying to navigate between the old system and the new one.\n\n“What’s neat about the backbone is that it’s similar to something you might find at Google or Facebook, but we built this with a relatively small team,” Dan Williams, head of production engineering at Dropbox told TechCrunch. And that small team had to build the backbone and move all of that the content, all while keeping the service up and running.\n\nUltimately though the company was willing to make this massive move because it craved control over its infrastructure. Williams admitted that when it comes to making a decision like this, there are always concessions, but in the end the trade-offs were worth it to them. “For us, it was about quality and control and management. We know there are solid third parties out there with [high] quality and performance, but we felt ours could be equal or even better because we know the system so well.”\n\nWilliams says for Dropbox, building the network was a business decision and it has had a positive impact on the business overall. “I think it could be argued in fact that anyone who has built a decent-sized network like this has had some effect on the business in a positive way that is actually building trust for the user and getting more users to adopt the product or service based on the quality of the service” Williams explained.\n\nThe new system has certainly had a positive impact on Dropbox’s reputation with enterprise IT too. Back in the day, Dropbox often had a bad rep with IT because of unauthorized usage inside large organizations. Today, the Dropbox Business line of products combined with this in-house infrastructure and network has created a level of trust they didn’t have before. Williams points out that they have such detailed insight into the networking operation, they can use that data as a sales driver, even though they didn’t end up charging for this change.\n\n“One of our core beliefs is providing a high-performance, low-expense product.” He believes that’s why they have been able to retain old customers through this transition, while also growing the user base over time.\n\nWhether the cost of ownership went down in real terms, the company believes it achieved its objectives by building it themselves. “While cost is always something that we consider, our goal with our network expansion was to improve performance, reliability, flexibility and control for our users — which we have succeeded in doing,” a company spokesperson told TechCrunch.\n\nThat build versus buy decision is never an easy one, especially for a company the size of Dropbox, which had to walk the line between the two systems while it made the transition, but today it appears to have paid off in a big way for them.', 'n_articles': 10}
INFO:werkzeug:127.0.0.1 - - [18/Sep/2017 23:04:11] "POST / HTTP/1.1" 200 -
INFO:werkzeug: * Detected change in '/home/diegoami/PycharmProjects/Newscollection/gensim_samples/gensim_lib.py', reloading
WARNING:werkzeug: * Debugger is active!
INFO:werkzeug: * Debugger PIN: 220-641-344
INFO:werkzeug: * Detected change in '/home/diegoami/PycharmProjects/Newscollection/gensim_samples/gensim_service.py', reloading
